{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook was made to create (and submit jobs for) JankyPipe, a pipeline that takes fastq files as input of Mycobacterium tuberculosis isolates, aligns the reads to H37Rv and calls variants. The output is a VCF file, a lineage call and a Qualimap report. This notebook also submits a job that runs JankyPipe on all of the *Replicate* isolates in our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from slurmpy import Slurm\n",
    "import vcf\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Function* to launch JankyPipe as a Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Launch_JankyPipe(fqf1 , fqf2 , tag , output_dir , scratch_dir , O2_SLURM_logs_dir):\n",
    "    \n",
    "    '''\n",
    "    This script launches a job to call variants for the input fastq files against H37Rv\n",
    "    using a number of packages. The important output (VCF, lineage info files, quality report)\n",
    "    is stored in the output directory while the intermediary files (SAMs, trimmed fastqs, BAM, etc)\n",
    "    are stored in a scratch directory.\n",
    "    '''\n",
    "    \n",
    "    #store all commands in a list\n",
    "    commands_list = []\n",
    "    \n",
    "    #change directory to scratch\n",
    "    commands_list.append( 'cd ' + scratch_dir )\n",
    "\n",
    "    ###################################\n",
    "    ### Load Necessary Modules ########\n",
    "    ###################################\n",
    "\n",
    "    #load perl\n",
    "    commands_list.append( 'module load perl/5.24.0' )\n",
    "\n",
    "    #load java\n",
    "    commands_list.append( 'module load java/jdk-1.8u112' )\n",
    "\n",
    "    #load BWA\n",
    "    commands_list.append( 'module load bwa/0.7.15' )\n",
    "\n",
    "    #load Samtools\n",
    "    commands_list.append( 'module load samtools/1.3.1' )\n",
    "\n",
    "    #load BCFtools\n",
    "    commands_list.append( 'module load bcftools/1.3.1' )\n",
    "\n",
    "    #load Picard\n",
    "    commands_list.append( 'module load picard/2.8.0' )\n",
    "\n",
    "    #Create Index files for Reference Genome\n",
    "    commands_list.append( 'mkdir RefGen' )\n",
    "\n",
    "    #copy reference genome over to RefGen folder\n",
    "    commands_list.append( 'cp /home/rv76/Farhat_Lab/Reference_Seqs/H37Rv/h37rv.fasta RefGen/TBRefGen.fasta' )\n",
    "\n",
    "    #change directory to RefGen folder\n",
    "    commands_list.append( 'cd RefGen' )\n",
    "\n",
    "    ###################################\n",
    "    ### Create Index Files for H37Rv ##\n",
    "    ###################################\n",
    "    commands_list.append( 'samtools faidx TBRefGen.fasta' )\n",
    "    commands_list.append( 'bwa index TBRefGen.fasta' )\n",
    "\n",
    "    RefGen = scratch_dir + '/RefGen/TBRefGen.fasta' #H37Rv reference\n",
    "\n",
    "    #go back to parent directory\n",
    "    commands_list.append( 'cd ..' )\n",
    "\n",
    "    ###################################\n",
    "    ### UnZip FastQ files #############\n",
    "    ###################################\n",
    "    fqf1_base_name = fqf1.split('/')[-1][0:-9]\n",
    "    fqf2_base_name = fqf2.split('/')[-1][0:-9]\n",
    "\n",
    "    #work with the unzipped files for the rest of the pipeline (after unzipping them)\n",
    "    fqf1_unzipped = scratch_dir + '/{}'.format(fqf1_base_name) + '.fastq'\n",
    "    fqf2_unzipped = scratch_dir + '/{}'.format(fqf2_base_name) + '.fastq'\n",
    "\n",
    "    commands_list.append( 'zcat {0} > {1}'.format(fqf1, fqf1_unzipped) )\n",
    "    commands_list.append( 'zcat {0} > {1}'.format(fqf2, fqf2_unzipped) )\n",
    "\n",
    "    #use the unzipped fastq files now\n",
    "    fqf1 = fqf1_unzipped\n",
    "    fqf2 = fqf2_unzipped\n",
    "    \n",
    "    ###################################\n",
    "    ### Clean FastQ read names ########\n",
    "    ###################################\n",
    "    \n",
    "    #delete any weird caracters from the read names in the FastQ files\n",
    "    commands_list.append( 'python /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/python_scripts/megapipe-correct-names-reads.py {}'.format(fqf1) )\n",
    "    commands_list.append( 'python /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/python_scripts/megapipe-correct-names-reads.py {}'.format(fqf2) )\n",
    "\n",
    "    ####################################\n",
    "    ### PRINSEQ (trim reads) ##########\n",
    "    ###################################\n",
    "\n",
    "    #create directory for prinseq in output directory\n",
    "    commands_list.append( 'mkdir ' + output_dir + '/prinseq' )\n",
    "\n",
    "    commands_list.append( 'perl /n/data1/hms/dbmi/farhat/bin/prinseq-lite-0.20.4/prinseq-lite.pl -fastq {0} -fastq2 {1} -out_format 3 -out_good {2}/{3}-trimmed -out_bad null -log {4}/{3}-trimmed.log -min_qual_mean 20 -verbose'.format(fqf1, fqf2, scratch_dir, tag , output_dir+'/prinseq') )\n",
    "\n",
    "    #use newly trimmed fastq files now\n",
    "    fqf1 = scratch_dir + '/{}'.format(tag) + '-trimmed_1.fastq'\n",
    "    fqf2 = scratch_dir + '/{}'.format(tag) + '-trimmed_2.fastq'\n",
    "\n",
    "    ######################################\n",
    "    ### BWA (align reads to reference) ###\n",
    "    ######################################\n",
    "\n",
    "    #create SAM file\n",
    "    samfile = scratch_dir + '/{}.sam'.format(tag)\n",
    "\n",
    "    #run BWA\n",
    "    commands_list.append( 'bwa mem -M {3} {0} {1} > {2}'.format(fqf1 , fqf2 , samfile , RefGen) )\n",
    "\n",
    "    #####################################\n",
    "    ### PICARD (sort & convert to BAM) ##\n",
    "    #####################################\n",
    "\n",
    "    #create BAM file\n",
    "    bamfile = scratch_dir + '/{0}.sorted.bam'.format(tag)\n",
    "\n",
    "    commands_list.append( 'java -Xmx16G -jar /n/data1/hms/dbmi/farhat/bin/picard/picard/build/libs/picard.jar SortSam INPUT={0} OUTPUT={1} SORT_ORDER=coordinate'.format(samfile, bamfile) )\n",
    "\n",
    "    ####################################\n",
    "    ### PICARD (remove duplicates) ####\n",
    "    ###################################\n",
    "\n",
    "    #create BAM file with removed duplicates\n",
    "    drbamfile = bamfile.replace(\".bam\", \".duprem.bam\")\n",
    "\n",
    "    #remove duplicates from BAM file\n",
    "    commands_list.append( \"java -Xmx32G -jar /n/data1/hms/dbmi/farhat/bin/picard/picard/build/libs/picard.jar MarkDuplicates I={0} O={1} REMOVE_DUPLICATES=true M={2} ASSUME_SORT_ORDER=coordinate\".format(bamfile, drbamfile, drbamfile[:-4]+'.metrics') )\n",
    "\n",
    "    ####################################\n",
    "    ### SAMTOOLS (to index BAM file) ###\n",
    "    ####################################\n",
    "    \n",
    "    commands_list.append( \"samtools index {0}\".format(drbamfile) )\n",
    "    \n",
    "    ######################################\n",
    "    ### QUALIMAP (quality of BAM file) ###\n",
    "    ######################################\n",
    "    \n",
    "    #store quality report, pilon VCF & lineage call information all in Output directory\n",
    "    commands_list.append( 'cd ' + output_dir )\n",
    "    commands_list.append( 'mkdir QualiMap' ) #make a folder for pilon output in output directory\n",
    "    commands_list.append( 'unset DISPLAY' ) #unset JAVA virtual machine variable [http://qualimap.bioinfo.cipf.es/doc_html/faq.html]\n",
    "    commands_list.append( \"/n/data1/hms/dbmi/farhat/bin/qualimap_v2.2.1/qualimap bamqc -bam {0} --outdir {1} --outfile {2}.pdf --outformat PDF\".format(drbamfile, output_dir+'/QualiMap', tag+'_stats') )\n",
    "\n",
    "    ###################################\n",
    "    ### PILON (call variants) #########\n",
    "    ###################################\n",
    "    \n",
    "    #store quality report, pilon VCF & lineage call information all in Output directory\n",
    "    commands_list.append( 'mkdir pilon' ) #make a folder for pilon output in output directory\n",
    "    out_pilon_dir = output_dir + '/pilon/' #variable for pilon output path\n",
    "\n",
    "    commands_list.append( 'java -Xmx32G -jar /n/data1/hms/dbmi/farhat/bin/pilon/pilon-1.22.jar --genome {0} --bam {1} --output {2} --outdir {3} --variant'.format(RefGen, drbamfile, tag, out_pilon_dir) )\n",
    "\n",
    "    #####################################\n",
    "    ### Luca's LINEAGE CALLING script ###\n",
    "    #####################################\n",
    "\n",
    "    #create directory \n",
    "    commands_list.append( 'mkdir ' + scratch_dir + '/fast-lineage-caller/' )#make a folder for lineage call in output directory\n",
    "    commands_list.append( 'mkdir ' + output_dir + '/fast-lineage-caller/' )#make a folder for lineage call in scratch directory\n",
    "\n",
    "    #create VRT file\n",
    "    vrtfile = scratch_dir + '/fast-lineage-caller/{}.vrt'.format(tag)\n",
    "\n",
    "    commands_list.append( 'cd ' + scratch_dir + '/fast-lineage-caller' )#change directory to store output in scratch\n",
    "\n",
    "    #convert VCF to VRT\n",
    "    commands_list.append( 'vrtTools-vcf2vrt.py {0} {1} 1'.format(out_pilon_dir+tag+'.vcf', vrtfile) )\n",
    "\n",
    "    #call lineage with SNP database an VRT file\n",
    "    commands_list.append( 'cd ' + output_dir + '/fast-lineage-caller' )#change directory to store output in VCF output\n",
    "\n",
    "    commands_list.append( 'FastLineageCaller-assign2lineage.py /home/rv76/Bio_Pipelines/fast-lineage-caller-master/example/db_snps.tsv ' + vrtfile + ' &> ' + 'lineage_call.txt' )\n",
    "\n",
    "    ###############################################################################################################\n",
    "    ######################################## SUBMIT as a job to O2 ################################################\n",
    "    ###############################################################################################################\n",
    "    \n",
    "    #append all commands in a single string to be submitted as a job\n",
    "    JankyPipe_job = ''\n",
    "    for command_i in commands_list:\n",
    "        JankyPipe_job = JankyPipe_job + '\\n' + command_i\n",
    "        \n",
    "        print command_i\n",
    "        print ' '\n",
    "    \n",
    "    \n",
    "    #directory where you want output + error files\n",
    "    os.chdir(O2_SLURM_logs_dir)\n",
    "\n",
    "    job_name = tag\n",
    "\n",
    "    s = Slurm(job_name , {'partition':'short' , 'n':'1' , 't':'0-10:00:00' , 'mem-per-cpu':'48G' , 'mail-type':'FAIL' , 'mail-user':'roger_vargas@g.harvard.edu'})\n",
    "\n",
    "    #submits the job\n",
    "    job_id = s.run(JankyPipe_job)\n",
    "\n",
    "    print job_name  + ' : ' +  str(job_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Replicate Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull all relevant sequenced isolate and corresponding FastQ file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotation = pd.read_csv('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/sample_annotation_files/REPLICATE_fastq_path_names.csv' , sep = ',').set_index('patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fastq_files</th>\n",
       "      <th>population</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>sample_order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I0002918-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru4092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0002918-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru3380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fastq_files population  \\\n",
       "patient_id                                                                 \n",
       "I0002918-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0002918-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "\n",
       "           run_ID sample_ID  sample_order  \n",
       "patient_id                                 \n",
       "I0002918-6    NaN  Peru4092             0  \n",
       "I0002918-6    NaN  Peru3380             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sample_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directories for each isolate and launch JankyPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT PARENT DIRECTORIES \n",
    "\n",
    "-   /n/scratch2/rv76/inhost_TB_dynamics_project/JankyPipe_REPLICATES/intermediary_files/\n",
    "\n",
    "    [to store intermediate files (unzipped fastq, trimmed fastq, SAM, sorted BAM, etc)]\n",
    "\n",
    "\n",
    "-   /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/output_REPLICATES/\n",
    "\n",
    "    [to store final files (pilon VCF, lineage, QualiMap, trim logs)]\n",
    "\n",
    "\n",
    "-   /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/O2_SLURM_logs_REPLICATES/\n",
    "\n",
    "    [to store submitted SLURM script, and SLURM error & verbose logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4092 : 23891126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891127\n",
      "submitted: Submitted batch job 23891128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru3380 : 23891127\n",
      "Peru2905 : 23891128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891129\n",
      "submitted: Submitted batch job 23891130\n",
      "submitted: Submitted batch job 23891131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4104 : 23891129\n",
      "Peru3016 : 23891130\n",
      "Peru4110 : 23891131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891132\n",
      "submitted: Submitted batch job 23891133\n",
      "submitted: Submitted batch job 23891134\n",
      "submitted: Submitted batch job 23891135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4133 : 23891132\n",
      "Peru3343 : 23891133\n",
      "Peru3324 : 23891134\n",
      "Peru4480 : 23891135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891136\n",
      "submitted: Submitted batch job 23891137\n",
      "submitted: Submitted batch job 23891138\n",
      "submitted: Submitted batch job 23891139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru5110 : 23891136\n",
      "00-R0025 : 23891137\n",
      "Peru4686 : 23891138\n",
      "00-R0308 : 23891139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891140\n",
      "submitted: Submitted batch job 23891141\n",
      "submitted: Submitted batch job 23891142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4690 : 23891140\n",
      "00-R1156 : 23891141\n",
      "Peru4689 : 23891142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891143\n",
      "submitted: Submitted batch job 23891144\n",
      "submitted: Submitted batch job 23891145\n",
      "submitted: Submitted batch job 23891146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-R1405 : 23891143\n",
      "Peru4683 : 23891144\n",
      "00-R1547 : 23891145\n",
      "Peru4904 : 23891146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891147\n",
      "submitted: Submitted batch job 23891148\n",
      "submitted: Submitted batch job 23891149\n",
      "submitted: Submitted batch job 23891150\n",
      "submitted: Submitted batch job 23891151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-R1549 : 23891147\n",
      "Peru5426 : 23891148\n",
      "00-R1562 : 23891149\n",
      "Peru5120 : 23891150\n",
      "01-R0153 : 23891151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891152\n",
      "submitted: Submitted batch job 23891153\n",
      "submitted: Submitted batch job 23891154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4671 : 23891152\n",
      "01-R0185 : 23891153\n",
      "Peru4519 : 23891154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891155\n",
      "submitted: Submitted batch job 23891156\n",
      "submitted: Submitted batch job 23891157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-R0238 : 23891155\n",
      "Peru5112 : 23891156\n",
      "01-R0239 : 23891157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891158\n",
      "submitted: Submitted batch job 23891159\n",
      "submitted: Submitted batch job 23891160\n",
      "submitted: Submitted batch job 23891161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4679 : 23891158\n",
      "01-R0265 : 23891159\n",
      "Peru4670 : 23891160\n",
      "01-R0272 : 23891161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891162\n",
      "submitted: Submitted batch job 23891163\n",
      "submitted: Submitted batch job 23891164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4908 : 23891162\n",
      "01-R0276 : 23891163\n",
      "Peru4664 : 23891164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891165\n",
      "submitted: Submitted batch job 23891166\n",
      "submitted: Submitted batch job 23891167\n",
      "submitted: Submitted batch job 23891168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-R0290 : 23891165\n",
      "Peru4675 : 23891166\n",
      "01-R0420 : 23891167\n",
      "Peru4698 : 23891168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891169\n",
      "submitted: Submitted batch job 23891170\n",
      "submitted: Submitted batch job 23891171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-R0685 : 23891169\n",
      "Peru4672 : 23891170\n",
      "01-R0737 : 23891171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891172\n",
      "submitted: Submitted batch job 23891173\n",
      "submitted: Submitted batch job 23891174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4938 : 23891172\n",
      "01-R0774 : 23891173\n",
      "Peru5074 : 23891174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891175\n",
      "submitted: Submitted batch job 23891176\n",
      "submitted: Submitted batch job 23891177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-R0878 : 23891175\n",
      "Peru4714 : 23891176\n",
      "01-R0880 : 23891177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891178\n",
      "submitted: Submitted batch job 23891179\n",
      "submitted: Submitted batch job 23891180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4922 : 23891178\n",
      "01-R0897 : 23891179\n",
      "Peru4707 : 23891180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891181\n",
      "submitted: Submitted batch job 23891182\n",
      "submitted: Submitted batch job 23891183\n",
      "submitted: Submitted batch job 23891184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-R0899 : 23891181\n",
      "Peru4694 : 23891182\n",
      "01-R0902 : 23891183\n",
      "Peru4700 : 23891184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891185\n",
      "submitted: Submitted batch job 23891186\n",
      "submitted: Submitted batch job 23891187\n",
      "submitted: Submitted batch job 23891188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-R0904 : 23891185\n",
      "Peru4716 : 23891186\n",
      "01-R0908 : 23891187\n",
      "Peru4719 : 23891188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891189\n",
      "submitted: Submitted batch job 23891190\n",
      "submitted: Submitted batch job 23891191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-R0909 : 23891189\n",
      "Peru4911 : 23891190\n",
      "01-R1018 : 23891191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891193\n",
      "submitted: Submitted batch job 23891194\n",
      "submitted: Submitted batch job 23891195\n",
      "submitted: Submitted batch job 23891196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4722 : 23891193\n",
      "01-R1305 : 23891194\n",
      "Peru4703 : 23891195\n",
      "01-R1309 : 23891196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891197\n",
      "submitted: Submitted batch job 23891198\n",
      "submitted: Submitted batch job 23891199\n",
      "submitted: Submitted batch job 23891200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4709 : 23891197\n",
      "01-R1321 : 23891198\n",
      "Peru4947 : 23891199\n",
      "01-R1386 : 23891200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891201\n",
      "submitted: Submitted batch job 23891202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru5410 : 23891201\n",
      "01-R1387 : 23891202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891203\n",
      "submitted: Submitted batch job 23891204\n",
      "submitted: Submitted batch job 23891205\n",
      "submitted: Submitted batch job 23891206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4914 : 23891203\n",
      "01-R1505 : 23891204\n",
      "Peru4711 : 23891205\n",
      "01-R1559 : 23891206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891207\n",
      "submitted: Submitted batch job 23891208\n",
      "submitted: Submitted batch job 23891209\n",
      "submitted: Submitted batch job 23891210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4953 : 23891207\n",
      "01-R1599 : 23891208\n",
      "Peru4919 : 23891209\n",
      "02-R0099 : 23891210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891211\n",
      "submitted: Submitted batch job 23891212\n",
      "submitted: Submitted batch job 23891213\n",
      "submitted: Submitted batch job 23891214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4957 : 23891211\n",
      "02-R0119 : 23891212\n",
      "Peru5418 : 23891213\n",
      "02-R0236 : 23891214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891215\n",
      "submitted: Submitted batch job 23891216\n",
      "submitted: Submitted batch job 23891217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4967 : 23891215\n",
      "02-R0328 : 23891216\n",
      "Peru5132 : 23891217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-R0417 : 23891218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891219\n",
      "submitted: Submitted batch job 23891220\n",
      "submitted: Submitted batch job 23891221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru5442 : 23891219\n",
      "02-R0812 : 23891220\n",
      "Peru5124 : 23891221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891222\n",
      "submitted: Submitted batch job 23891223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-R0848 : 23891222\n",
      "Peru5443 : 23891223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891224\n",
      "submitted: Submitted batch job 23891225\n",
      "submitted: Submitted batch job 23891226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-R1444 : 23891224\n",
      "Peru4972 : 23891225\n",
      "02-R1589 : 23891226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891227\n",
      "submitted: Submitted batch job 23891228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru5143 : 23891227\n",
      "02-R1641 : 23891228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891229\n",
      "submitted: Submitted batch job 23891230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru5090 : 23891229\n",
      "02-R1645 : 23891230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891231\n",
      "submitted: Submitted batch job 23891232\n",
      "submitted: Submitted batch job 23891233\n",
      "submitted: Submitted batch job 23891234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru5088 : 23891231\n",
      "02-R1742 : 23891232\n",
      "Peru4963 : 23891233\n",
      "02-R1825 : 23891234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891235\n",
      "submitted: Submitted batch job 23891236\n",
      "submitted: Submitted batch job 23891237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4720 : 23891235\n",
      "02-R1945 : 23891236\n",
      "Peru4653 : 23891237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891238\n",
      "submitted: Submitted batch job 23891239\n",
      "submitted: Submitted batch job 23891240\n",
      "submitted: Submitted batch job 23891241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-R0061 : 23891238\n",
      "Peru4994 : 23891239\n",
      "03-R0221 : 23891240\n",
      "Peru4974 : 23891241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891242\n",
      "submitted: Submitted batch job 23891243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-R0319 : 23891242\n",
      "Peru5137 : 23891243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891244\n",
      "submitted: Submitted batch job 23891245\n",
      "submitted: Submitted batch job 23891246\n",
      "submitted: Submitted batch job 23891247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-R0915 : 23891244\n",
      "Peru4574 : 23891245\n",
      "04-R0266 : 23891246\n",
      "Peru5025 : 23891247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891248\n",
      "submitted: Submitted batch job 23891249\n",
      "submitted: Submitted batch job 23891250\n",
      "submitted: Submitted batch job 23891251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98-R454 : 23891248\n",
      "Peru5119 : 23891249\n",
      "98-R660 : 23891250\n",
      "Peru5037 : 23891251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891252\n",
      "submitted: Submitted batch job 23891253\n",
      "submitted: Submitted batch job 23891254\n",
      "submitted: Submitted batch job 23891255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98-R790 : 23891252\n",
      "Peru5029 : 23891253\n",
      "99-10364 : 23891254\n",
      "Peru4659 : 23891255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891256\n",
      "submitted: Submitted batch job 23891257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99-R545 : 23891256\n",
      "Peru4662 : 23891257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891258\n",
      "submitted: Submitted batch job 23891259\n",
      "submitted: Submitted batch job 23891260\n",
      "submitted: Submitted batch job 23891261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99-R719 : 23891258\n",
      "Peru4688 : 23891259\n",
      "99-R862 : 23891260\n",
      "Peru5420 : 23891261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891262\n",
      "submitted: Submitted batch job 23891263\n",
      "submitted: Submitted batch job 23891264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99-R887 : 23891262\n",
      "Peru4685 : 23891263\n",
      "99-R893 : 23891264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891265\n",
      "submitted: Submitted batch job 23891266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru5146 : 23891265\n",
      "99-R995 : 23891266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891267\n",
      "submitted: Submitted batch job 23891268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4702 : 23891267\n",
      "02-R1447 : 23891268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891269\n",
      "submitted: Submitted batch job 23891270\n",
      "submitted: Submitted batch job 23891271\n",
      "submitted: Submitted batch job 23891272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4948 : 23891269\n",
      "02-R1683 : 23891270\n",
      "Peru5434 : 23891271\n",
      "03-R0419 : 23891272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891273\n",
      "submitted: Submitted batch job 23891274\n",
      "submitted: Submitted batch job 23891275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4726 : 23891273\n",
      "03-R0979 : 23891274\n",
      "Peru5414 : 23891275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891276\n",
      "submitted: Submitted batch job 23891277\n",
      "submitted: Submitted batch job 23891278\n",
      "submitted: Submitted batch job 23891279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-R0191 : 23891276\n",
      "Peru4706 : 23891277\n",
      "02-R0325 : 23891278\n",
      "Peru4977 : 23891279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891280\n",
      "submitted: Submitted batch job 23891281\n",
      "submitted: Submitted batch job 23891282\n",
      "submitted: Submitted batch job 23891283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-R0861 : 23891280\n",
      "Peru4668 : 23891281\n",
      "02-R0948 : 23891282\n",
      "Peru5117 : 23891283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-R1527 : 23891284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891285\n",
      "submitted: Submitted batch job 23891286\n",
      "submitted: Submitted batch job 23891287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peru4665 : 23891285\n",
      "03-R0324 : 23891286\n",
      "ERR1352350 : 23891287\n",
      "ERR1352351 : 23891288\n",
      "ERR1352352 : 23891289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23891288\n",
      "submitted: Submitted batch job 23891289\n"
     ]
    }
   ],
   "source": [
    "for isolate_i in range(0 , np.shape(sample_annotation)[0]):\n",
    "    \n",
    "    isolate_fastq_paths = sample_annotation.iloc[isolate_i , 0]\n",
    "\n",
    "    #paths & names for fastq files\n",
    "    fqf1 = isolate_fastq_paths.split(';')[0]\n",
    "    fqf2 = isolate_fastq_paths.split(';')[1]\n",
    "    \n",
    "    #get the tag ID for the fastq files (same as ID for fastq files)\n",
    "    \n",
    "    #check to see if 'CETR' , 'POOLS' or 'TRAUNER'\n",
    "    if (fqf1.split('/')[-1][:3] == 'Per') or (fqf1.split('/')[-1][:3] == 'ERR'): #CETR or TRAUNER sample\n",
    "        tag = fqf1.split('/')[-1].split('_')[0]\n",
    "        \n",
    "    else: #POOLS sample\n",
    "        tag = fqf1.split('/')[-1].split('.1')[0]\n",
    "        \n",
    "\n",
    "    #where pilon VCF and lineage information will be stored [LAB FOLDER]\n",
    "    output_dir = '/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/output_REPLICATES/' + tag\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir)\n",
    "    elif not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "        \n",
    "    #where everything else happens (trimming, aligning, etc.) [SCRATCH FOLDER]\n",
    "    scratch_dir = '/n/scratch2/rv76/inhost_TB_dynamics_project/JankyPipe_REPLICATES/intermediary_files/' + tag\n",
    "    if os.path.exists(scratch_dir):\n",
    "        shutil.rmtree(scratch_dir)\n",
    "        os.makedirs(scratch_dir)\n",
    "    elif not os.path.exists(scratch_dir):\n",
    "        os.makedirs(scratch_dir)\n",
    "        \n",
    "\n",
    "    #store O2 job log files [LAB FOLDER]\n",
    "    O2_SLURM_logs_dir = '/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/O2_SLURM_logs_REPLICATES/' + tag\n",
    "    if os.path.exists(O2_SLURM_logs_dir):\n",
    "        shutil.rmtree(O2_SLURM_logs_dir)\n",
    "        os.makedirs(O2_SLURM_logs_dir)\n",
    "    elif not os.path.exists(O2_SLURM_logs_dir):\n",
    "        os.makedirs(O2_SLURM_logs_dir)\n",
    "\n",
    "    #Launch JankyPipe after making necessary directories!!!\n",
    "    Launch_JankyPipe(fqf1 , fqf2 , tag , output_dir , scratch_dir , O2_SLURM_logs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save tags (corresponds to folder names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store tags to each sample\n",
    "tag_list = []\n",
    "\n",
    "for isolate_i in range(0 , np.shape(sample_annotation)[0]):\n",
    "    \n",
    "    isolate_fastq_paths = sample_annotation.iloc[isolate_i , 0]\n",
    "\n",
    "    #paths & names for fastq files\n",
    "    fqf1 = isolate_fastq_paths.split(';')[0]\n",
    "\n",
    "    #get the tag ID for the fastq files (same as ID for fastq files)\n",
    "    \n",
    "    #check to see if 'CETR' , 'POOLS' or 'TRAUNER'\n",
    "    if (fqf1.split('/')[-1][:3] == 'Per') or (fqf1.split('/')[-1][:3] == 'ERR'): #CETR or TRAUNER sample\n",
    "        tag = fqf1.split('/')[-1].split('_')[0]\n",
    "        \n",
    "    else: #POOLS sample\n",
    "        tag = fqf1.split('/')[-1].split('.1')[0]\n",
    "\n",
    "    tag_list.append(tag)\n",
    "    \n",
    "sample_annotation['tag'] = tag_list \n",
    "\n",
    "#store as CSV\n",
    "sample_annotation.to_csv('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/sample_annotation_files/REPLICATE_fastq_path_names_and_JankyPipe_tags.csv' , sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fastq_files</th>\n",
       "      <th>population</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>sample_order</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I0002918-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru4092</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0002918-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru3380</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0003710-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru2905</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0003710-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru4104</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru4104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0003922-7</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru3016</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru3016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fastq_files population  \\\n",
       "patient_id                                                                 \n",
       "I0002918-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0002918-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0003710-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0003710-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0003922-7  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "\n",
       "           run_ID sample_ID  sample_order       tag  \n",
       "patient_id                                           \n",
       "I0002918-6    NaN  Peru4092             0  Peru4092  \n",
       "I0002918-6    NaN  Peru3380             0  Peru3380  \n",
       "I0003710-6    NaN  Peru2905             0  Peru2905  \n",
       "I0003710-6    NaN  Peru4104             0  Peru4104  \n",
       "I0003922-7    NaN  Peru3016             0  Peru3016  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fastq_files</th>\n",
       "      <th>population</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>sample_order</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>replicate_pair_74</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>CP_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru4665</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru4665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replicate_pair_74</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/fastq_db/pools/03-R03...</td>\n",
       "      <td>CP_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03-R0324</td>\n",
       "      <td>0</td>\n",
       "      <td>03-R0324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P12</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/fastq_db/trauner/ERR1...</td>\n",
       "      <td>TR_REP</td>\n",
       "      <td>ERR1352350</td>\n",
       "      <td>SAMEA3921015</td>\n",
       "      <td>0</td>\n",
       "      <td>ERR1352350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P12</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/fastq_db/trauner/ERR1...</td>\n",
       "      <td>TR_REP</td>\n",
       "      <td>ERR1352351</td>\n",
       "      <td>SAMEA3921016</td>\n",
       "      <td>0</td>\n",
       "      <td>ERR1352351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P12</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/fastq_db/trauner/ERR1...</td>\n",
       "      <td>TR_REP</td>\n",
       "      <td>ERR1352352</td>\n",
       "      <td>SAMEA3921017</td>\n",
       "      <td>0</td>\n",
       "      <td>ERR1352352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         fastq_files  \\\n",
       "patient_id                                                             \n",
       "replicate_pair_74  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...   \n",
       "replicate_pair_74  /n/data1/hms/dbmi/farhat/fastq_db/pools/03-R03...   \n",
       "P12                /n/data1/hms/dbmi/farhat/fastq_db/trauner/ERR1...   \n",
       "P12                /n/data1/hms/dbmi/farhat/fastq_db/trauner/ERR1...   \n",
       "P12                /n/data1/hms/dbmi/farhat/fastq_db/trauner/ERR1...   \n",
       "\n",
       "                  population      run_ID     sample_ID  sample_order  \\\n",
       "patient_id                                                             \n",
       "replicate_pair_74     CP_REP         NaN      Peru4665             0   \n",
       "replicate_pair_74     CP_REP         NaN      03-R0324             0   \n",
       "P12                   TR_REP  ERR1352350  SAMEA3921015             0   \n",
       "P12                   TR_REP  ERR1352351  SAMEA3921016             0   \n",
       "P12                   TR_REP  ERR1352352  SAMEA3921017             0   \n",
       "\n",
       "                          tag  \n",
       "patient_id                     \n",
       "replicate_pair_74    Peru4665  \n",
       "replicate_pair_74    03-R0324  \n",
       "P12                ERR1352350  \n",
       "P12                ERR1352351  \n",
       "P12                ERR1352352  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine if jobs ran successfully or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_run = []\n",
    "\n",
    "for isolate_i in range(0 , np.shape(sample_annotation)[0]):\n",
    "\n",
    "    #get the tag ID for the fastq files (same as ID for fastq files)\n",
    "    tag = sample_annotation.tag[isolate_i]\n",
    "\n",
    "    #where pilon VCF and lineage information will be stored [LAB FOLDER]\n",
    "    output_dir = '/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/output_REPLICATES/' + tag\n",
    "    \n",
    "    #check to see 'Lineage Call' folder exists in the output directory (last thing that is run in JankyPipe)\n",
    "    if os.path.exists(output_dir + '/fast-lineage-caller/'):\n",
    "        \n",
    "        successful_run.append('yes')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        successful_run.append('no')\n",
    "        \n",
    "sample_annotation['successful_run'] = successful_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fastq_files</th>\n",
       "      <th>population</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>sample_order</th>\n",
       "      <th>tag</th>\n",
       "      <th>successful_run</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>replicate_pair_63</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/fastq_db/pools/99-R89...</td>\n",
       "      <td>CP_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99-R893</td>\n",
       "      <td>0</td>\n",
       "      <td>99-R893</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         fastq_files  \\\n",
       "patient_id                                                             \n",
       "replicate_pair_63  /n/data1/hms/dbmi/farhat/fastq_db/pools/99-R89...   \n",
       "\n",
       "                  population run_ID sample_ID  sample_order      tag  \\\n",
       "patient_id                                                             \n",
       "replicate_pair_63     CP_REP    NaN   99-R893             0  99-R893   \n",
       "\n",
       "                  successful_run  \n",
       "patient_id                        \n",
       "replicate_pair_63             no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation[sample_annotation.successful_run == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sample_annotation[sample_annotation.successful_run == 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop any isolate from sample annotation that DID NOT have a successful run in JankyPipe (and corresponding paired isolate)\n",
    "sample_annotation.drop('replicate_pair_63' , inplace = True)\n",
    "\n",
    "#store as CSV\n",
    "sample_annotation.to_csv('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/sample_annotation_files/REPLICATE_fastq_path_names_and_JankyPipe_tags.csv' , sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Run isolates through pipeline that hit a run-timelimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR1352352 : 23966782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 23966782\n"
     ]
    }
   ],
   "source": [
    "#isolates that don't have a lineage-call directory didn't finish running through pipeline\n",
    "sample_annotation_ReRun = sample_annotation[sample_annotation.successful_run == 'no']\n",
    "\n",
    "#if path already exists, remove current contents, then recreate empty directory\n",
    "#if path doesn't exist, create new directory\n",
    "\n",
    "for isolate_i in range(0 , np.shape(sample_annotation_ReRun)[0]):\n",
    "    \n",
    "    isolate_fastq_paths = sample_annotation_ReRun.iloc[isolate_i , 0]\n",
    "\n",
    "    #paths & names for fastq files\n",
    "    fqf1 = isolate_fastq_paths.split(';')[0]\n",
    "    fqf2 = isolate_fastq_paths.split(';')[1]\n",
    "\n",
    "    #get the tag ID for the fastq files (same as ID for fastq files)\n",
    "    tag = fqf1.split('/')[-1].split('_')[0]\n",
    "\n",
    "    #where pilon VCF and lineage information will be stored [LAB FOLDER]\n",
    "    output_dir = '/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/output_REPLICATES/' + tag\n",
    "    \n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir)\n",
    "    elif not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "\n",
    "    #where everything else happens (trimming, aligning, etc.) [SCRATCH FOLDER]\n",
    "    scratch_dir = '/n/scratch2/rv76/inhost_TB_dynamics_project/JankyPipe_REPLICATES/intermediary_files/' + tag\n",
    "    \n",
    "    if os.path.exists(scratch_dir):\n",
    "        shutil.rmtree(scratch_dir)\n",
    "        os.makedirs(scratch_dir)\n",
    "    elif not os.path.exists(scratch_dir):\n",
    "        os.makedirs(scratch_dir)\n",
    "\n",
    "        \n",
    "    #store O2 job log files [LAB FOLDER]\n",
    "    O2_SLURM_logs_dir = '/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/O2_SLURM_logs_REPLICATES/' + tag\n",
    "    \n",
    "    if os.path.exists(O2_SLURM_logs_dir):\n",
    "        shutil.rmtree(O2_SLURM_logs_dir)\n",
    "        os.makedirs(O2_SLURM_logs_dir)\n",
    "    elif not os.path.exists(O2_SLURM_logs_dir):\n",
    "        os.makedirs(O2_SLURM_logs_dir)\n",
    "\n",
    "        \n",
    "    #Launch JankyPipe after making necessary directories!!!\n",
    "    Launch_JankyPipe(fqf1 , fqf2 , tag , output_dir , scratch_dir , O2_SLURM_logs_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
