{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from slurmpy import Slurm\n",
    "import vcf\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] Run Kraken2 on sequenced isolates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get sample annotation & (trimmed) fastq paths for all sequenced samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_annotation = pd.read_csv('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/sample_annotation_files/REPLICATE_fastq_path_names_and_JankyPipe_tags.csv' , sep  = ',').set_index('patient_id')\n",
    "\n",
    "#drop duplicate isolates (may have arisen from Trauner fudging of annotation file)\n",
    "drop_duplicate_isolate_filter = [not redundant for redundant in list( sample_annotation.duplicated('tag') ) ]\n",
    "sample_annotation = sample_annotation[drop_duplicate_isolate_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sample_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fastq_files</th>\n",
       "      <th>population</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>sample_ID</th>\n",
       "      <th>sample_order</th>\n",
       "      <th>tag</th>\n",
       "      <th>successful_run</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I0002918-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru4092</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru4092</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0002918-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru3380</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru3380</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0003710-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru2905</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru2905</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0003710-6</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru4104</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru4104</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0003922-7</th>\n",
       "      <td>/n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...</td>\n",
       "      <td>LC_REP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru3016</td>\n",
       "      <td>0</td>\n",
       "      <td>Peru3016</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fastq_files population  \\\n",
       "patient_id                                                                 \n",
       "I0002918-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0002918-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0003710-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0003710-6  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "I0003922-7  /n/data1/hms/dbmi/farhat/cetr_strains/good_wgs...     LC_REP   \n",
       "\n",
       "           run_ID sample_ID  sample_order       tag successful_run  \n",
       "patient_id                                                          \n",
       "I0002918-6    NaN  Peru4092             0  Peru4092            yes  \n",
       "I0002918-6    NaN  Peru3380             0  Peru3380            yes  \n",
       "I0003710-6    NaN  Peru2905             0  Peru2905            yes  \n",
       "I0003710-6    NaN  Peru4104             0  Peru4104            yes  \n",
       "I0003922-7    NaN  Peru3016             0  Peru3016            yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Function* to submit job to run Kraken on sequnced isolates as a job for each isolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_kraken2_on_isolate(isolate_tag):\n",
    "    \n",
    "    '''\n",
    "    This function launches a job that runs a sequenced isolate through Kraken2.\n",
    "    The output is an output text file with information about the classification \n",
    "    of each (paired) read from the sequenced output and a report text file with\n",
    "    aggregate level information on how many reads were assigned to each taxon.\n",
    "    '''\n",
    "\n",
    "    #directory where timmed-fastq files are stored\n",
    "    scratch_dir = '/n/scratch2/rv76/inhost_TB_dynamics_project/JankyPipe_REPLICATES/intermediary_files/'\n",
    "\n",
    "    #paths & names for (trimmed) fastq files\n",
    "    fqf1_trimmed = scratch_dir + isolate_tag + '/' + isolate_tag + '-trimmed_1.fastq'\n",
    "    fqf2_trimmed = scratch_dir + isolate_tag + '/' + isolate_tag + '-trimmed_2.fastq'\n",
    "\n",
    "    #directory where we will store Kraken output\n",
    "    output_dir = '/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/output_REPLICATES/'\n",
    "\n",
    "    #make directory for kraken2 output (if one already exists, remove it)\n",
    "    kraken2_dir = output_dir + isolate_tag + '/kraken2/'\n",
    "    \n",
    "    #if directory for Kraken output doesn't exist, submit a job to run Kraken\n",
    "    if not os.path.exists(kraken2_dir):\n",
    "        \n",
    "        os.makedirs(kraken2_dir) #make directory to store Kraken output\n",
    "\n",
    "        #construct job\n",
    "        kraken_job = 'kraken2 --paired --use-names --report ' + kraken2_dir + isolate_tag + '_trimmed_report.txt ' + '--output ' + kraken2_dir + isolate_tag + '_trimmed_output.txt ' +  fqf1_trimmed + ' ' + fqf2_trimmed  + ' ' + '--db /n/data1/hms/dbmi/farhat/Roger/kraken_db'\n",
    "\n",
    "        #submit job\n",
    "        #directory where you want output + error files\n",
    "        os.chdir(kraken2_dir)\n",
    "\n",
    "        job_name = isolate_tag\n",
    "        s = Slurm(job_name \n",
    "                  , {'partition':'short' , 'n':'1' , 't':'0-3:00:00' , 'mem-per-cpu':'64G' , 'mail-type':'FAIL' , 'mail-user':'roger_vargas@g.harvard.edu'})\n",
    "\n",
    "        #submits the job\n",
    "        job_id = s.run(kraken_job)\n",
    "\n",
    "        print job_name  + ' : ' +  str(job_id)\n",
    "    \n",
    "    #if the directory for Kraken files DOES exist but an output file is missing, submit a job to run Kraken\n",
    "    elif os.path.exists(kraken2_dir):\n",
    "        \n",
    "        #check to see if report & output txt files from Kraken run already exist, if either file is missing (submit job and) re-run kraken\n",
    "        if ( isolate_tag + '_trimmed_report.txt' not in os.listdir(kraken2_dir) ) or ( isolate_tag + '_trimmed_output.txt' not in os.listdir(kraken2_dir) ):\n",
    "\n",
    "            shutil.rmtree(kraken2_dir) #remove all current files\n",
    "            os.makedirs(kraken2_dir) #re-make directory to store Kraken output\n",
    "\n",
    "            #construct job\n",
    "            kraken_job = 'kraken2 --paired --use-names --report ' + kraken2_dir + isolate_tag + '_trimmed_report.txt ' + '--output ' + kraken2_dir + isolate_tag + '_trimmed_output.txt ' +  fqf1_trimmed + ' ' + fqf2_trimmed  + ' ' + '--db /n/data1/hms/dbmi/farhat/Roger/kraken_db'\n",
    "\n",
    "            #submit job\n",
    "            #directory where you want output + error files\n",
    "            os.chdir(kraken2_dir)\n",
    "\n",
    "            job_name = isolate_tag\n",
    "            s = Slurm(job_name \n",
    "                      , {'partition':'short' , 'n':'1' , 't':'0-3:00:00' , 'mem-per-cpu':'64G' , 'mail-type':'FAIL' , 'mail-user':'roger_vargas@g.harvard.edu'})\n",
    "\n",
    "            #submits the job\n",
    "            job_id = s.run(kraken_job)\n",
    "\n",
    "            print job_name  + ' : ' +  str(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for isolate_i in range(0 , np.shape(sample_annotation)[0]):\n",
    "    \n",
    "    #pull tag from sample annotation\n",
    "    isolate_tag = sample_annotation.iloc[isolate_i , 5]\n",
    "    \n",
    "    #run Kraken2 on sequenced isolate\n",
    "    run_kraken2_on_isolate(isolate_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Parse through Kraken results & calculate proportion of reads assigned to MTBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend for Kraken Report output\n",
    "\n",
    "A - Percentage of fragments covered by the clade rooted at this taxon\n",
    "\n",
    "B - Number of fragments covered by the clade rooted at this taxon\n",
    "\n",
    "C - Number of fragments assigned directly to this taxon\n",
    "\n",
    "D - A rank code, indicating (U)nclassified, (R)oot, (D)omain, (K)ingdom,\n",
    "   (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies.\n",
    "   Taxa that are not at any of these 10 ranks have a rank code that is\n",
    "   formed by using the rank code of the closest ancestor rank with\n",
    "   a number indicating the distance from that rank.  E.g., \"G2\" is a\n",
    "   rank code indicating a taxon is between genus and species and the\n",
    "   grandparent taxon is at the genus rank.\n",
    "\n",
    "E - NCBI taxonomic ID number\n",
    "\n",
    "F - Indented scientific name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Function* that parses through Kraken report and returns the proportion of reads (from sequencing run) that were identied as matching to MTBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prop_reads_MTBC(kraken_report_path , kraken_MTBC_prop_output_path):\n",
    "    \n",
    "    '''\n",
    "    This function parses through the kraken report for a sequenced isolate\n",
    "    and writes a text file with the proportion of reads that were identified\n",
    "    as MTBC from that sequenced isolate.\n",
    "    '''\n",
    "    \n",
    "    #load Report spit out by Kraken\n",
    "    kraken_report = pd.read_csv(kraken_report_path , sep = '\\t' , names = ['A' , 'B' , 'C' , 'D' , 'E' , 'F'])\n",
    "\n",
    "    #(1)\n",
    "    #get total number of reads that were run through Kraken (Classified + Unclassified)\n",
    "    CLASSIFIED_read_count = list(kraken_report[kraken_report.E == 1].B)[0]\n",
    "    UNCLASSIFIED_read_count = list(kraken_report[kraken_report.E == 0].B)[0]\n",
    "    TOTAL_read_count = CLASSIFIED_read_count + UNCLASSIFIED_read_count\n",
    "\n",
    "    #(2)\n",
    "    #Scientific IDs of Interest - taxon IDs for which we want read count for, reads assigned to every taxon between ROOT & MYCOBACTERIUM\n",
    "    ROOT_to_MYCOBACTERIUM_taxon_IDs = [1 , 131567 , 2 , 1783272 , 201174 , 1760 , 85007 , 1762 , 1763]\n",
    "\n",
    "    #get total number of reads assignd to taxon between 'root' & 'Mycobacterium' \n",
    "    ROOT_to_MYCOBACTERIUM_read_count = 0\n",
    "\n",
    "    #iterate through every taxon id and get number of reads assigned to each id\n",
    "    for taxon_id in ROOT_to_MYCOBACTERIUM_taxon_IDs:\n",
    "\n",
    "        ROOT_to_MYCOBACTERIUM_read_count = ROOT_to_MYCOBACTERIUM_read_count + list(kraken_report[kraken_report.E == taxon_id].C)[0]\n",
    "\n",
    "    #(3)\n",
    "    #get total number of reads assigned to 'Mycobacterium tuberculosis complex' & every taxon below \n",
    "    MTBC_and_BELOW_read_count = list(kraken_report[kraken_report.E == 77643].B)[0]\n",
    "\n",
    "    #calculate total number of reads assigned to MTBC\n",
    "    prop_reads_MTBC = float(ROOT_to_MYCOBACTERIUM_read_count + MTBC_and_BELOW_read_count) / float(TOTAL_read_count)\n",
    "    \n",
    "    #write the proportion of reads that were assigned to MTBC to a text file in the same directory as Kraken report & output\n",
    "    f = open(kraken_MTBC_prop_output_path,'w')\n",
    "    f.write( str(prop_reads_MTBC) )\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for isolate_i in range(0 , np.shape(sample_annotation)[0]):\n",
    "    \n",
    "    #directory where Kraken output is stored\n",
    "    output_dir = '/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/output_REPLICATES/'\n",
    "    \n",
    "    #pull tag from sample annotation\n",
    "    isolate_tag = sample_annotation.iloc[isolate_i , 5]\n",
    "    \n",
    "    #directory for kraken2 output\n",
    "    kraken2_dir = output_dir + isolate_tag + '/kraken2/'\n",
    "\n",
    "    #parse through kraken output and calculate % of reads in MTBC\n",
    "    get_prop_reads_MTBC( kraken2_dir + isolate_tag + '_trimmed_report.txt' , kraken2_dir + isolate_tag + '_MTBC_prop_from_Kraken.txt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
