{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook was created to classify each sample from the 307 patients (N=614) as *Susceptible* or *Resistant* for several antibiotics SNPs detected in VCF files and Predictive Resistance Mutations from Farhat et al. 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcf\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from pylab import plot, show, savefig, xlim, figure, hold, ylim, legend, boxplot, setp, axes\n",
    "from itertools import compress\n",
    "from pylab import MaxNLocator\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import gridspec\n",
    "import ast\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import fastcluster\n",
    "from sklearn import cluster, datasets\n",
    "import scipy.cluster.hierarchy as hier\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import Bio\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio import pairwise2\n",
    "from Bio import SeqIO\n",
    "from Bio.Graphics import GenomeDiagram\n",
    "from Bio.SeqUtils import GC\n",
    "\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from StringIO import StringIO\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.Seq import MutableSeq\n",
    "import itertools\n",
    "\n",
    "import networkx as nx\n",
    "import scipy\n",
    "\n",
    "import datetime as dt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import decimal\n",
    "\n",
    "#for exporting to Adobe Illustrator\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Sample Annotation file for all *longitudinal* isolates pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotation = pd.read_csv('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/sample_annotation_files/Table S2B for DR genotyping.csv' , sep  = ',').set_index('Patient ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study Source</th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Sample Order</th>\n",
       "      <th>tag</th>\n",
       "      <th>Isolate Type</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Filtered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I0005973-8</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQFF00000000</td>\n",
       "      <td>Peru3062</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru3062</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>6/27/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005973-8</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQKH00000000</td>\n",
       "      <td>Peru3315</td>\n",
       "      <td>2</td>\n",
       "      <td>Peru3315</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>8/20/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005229-5</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQAO00000000</td>\n",
       "      <td>Peru2908</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru2908</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>3/30/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005229-5</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQKD00000000</td>\n",
       "      <td>Peru3278</td>\n",
       "      <td>2</td>\n",
       "      <td>Peru3278</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>8/6/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005235-2</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQBA00000000</td>\n",
       "      <td>Peru2921</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru2921</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>4/21/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Study Source        Run ID Sample ID  Sample Order  \\\n",
       "Patient ID                                                              \n",
       "I0005973-8  Farhat et. al. 2019  MQFF00000000  Peru3062             1   \n",
       "I0005973-8  Farhat et. al. 2019  MQKH00000000  Peru3315             2   \n",
       "I0005229-5  Farhat et. al. 2019  MQAO00000000  Peru2908             1   \n",
       "I0005229-5  Farhat et. al. 2019  MQKD00000000  Peru3278             2   \n",
       "I0005235-2  Farhat et. al. 2019  MQBA00000000  Peru2921             1   \n",
       "\n",
       "                 tag          Isolate Type    Dates Filtered  \n",
       "Patient ID                                                    \n",
       "I0005973-8  Peru3062  Longitudinal Isolate  6/27/12      NaN  \n",
       "I0005973-8  Peru3315  Longitudinal Isolate  8/20/12      NaN  \n",
       "I0005229-5  Peru2908  Longitudinal Isolate  3/30/12      NaN  \n",
       "I0005229-5  Peru3278  Longitudinal Isolate   8/6/12      NaN  \n",
       "I0005235-2  Peru2921  Longitudinal Isolate  4/21/12      NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sample_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SNPs associated with drug resistance from Farhat et. al. 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_drug_res_variants(filepath):\n",
    "    \n",
    "    AR_variants_DF = pd.DataFrame(columns = ['variant_type' , 'region_type' , 'ref_position' , 'ref_allele' , 'alt_allele'])\n",
    "    with open(filepath) as fp:  \n",
    "       for cnt, line in enumerate(fp):\n",
    "           #print(\"Line {}: {}\".format(cnt, line))\n",
    "            AR_variants_DF.loc[cnt , :] = [line.split('_')[0] , line.split('_')[1] , int(line.split('_')[2]) , line.split('_')[3][0] , line.split('_')[3][1]]\n",
    "\n",
    "    #sort values by Reference Position\n",
    "    AR_variants_DF.sort_values(by = 'ref_position' , ascending = True , inplace = True)\n",
    "    \n",
    "    #drop duplicate reference positions\n",
    "    duplicated_variants = list( AR_variants_DF[AR_variants_DF.duplicated(subset = 'ref_position' , keep = 'first')].index )\n",
    "    AR_variants_DF.drop(duplicated_variants , axis = 0 , inplace = True)\n",
    "\n",
    "    #drop any variant that isn't a SNP and re-index\n",
    "    AR_variants_DF = AR_variants_DF[AR_variants_DF.variant_type == 'SNP']\n",
    "    AR_variants_DF.reset_index(drop = True , inplace = True)\n",
    "    \n",
    "    return AR_variants_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_ALL_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations.txt')\n",
    "AR_RIF_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_RIF.txt')\n",
    "AR_INH_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_INH.txt')\n",
    "AR_AMK_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_AMK.txt')\n",
    "AR_CAP_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_CAP.txt')\n",
    "AR_CIP_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_CIP.txt')\n",
    "AR_EMB_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_EMB.txt')\n",
    "AR_ETH_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_ETH.txt')\n",
    "AR_KAN_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_KAN.txt')\n",
    "AR_LEVO_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_LEVO.txt')\n",
    "AR_OFLX_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_OFLX.txt')\n",
    "AR_PAS_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_PAS.txt')\n",
    "AR_PZA_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_PZA.txt')\n",
    "AR_STR_variants_DF = load_drug_res_variants('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/predictive_AR_mutations/Table_S17_238_DR_mutations_STR.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant_type</th>\n",
       "      <th>region_type</th>\n",
       "      <th>ref_position</th>\n",
       "      <th>ref_allele</th>\n",
       "      <th>alt_allele</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNP</td>\n",
       "      <td>CN</td>\n",
       "      <td>6735</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SNP</td>\n",
       "      <td>CN</td>\n",
       "      <td>7563</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNP</td>\n",
       "      <td>CN</td>\n",
       "      <td>7566</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant_type region_type ref_position ref_allele alt_allele\n",
       "0          SNP          CN         6735          A          C\n",
       "1          SNP          CN         7563          G          T\n",
       "2          SNP          CN         7566          G          A"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AR_ALL_variants_DF.head(n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(AR_ALL_variants_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "H37Rv_positions_of_interest = list( AR_ALL_variants_DF.ref_position ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of Resistance mutations from DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_RIF_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_RIF_variants_DF.ref_position , AR_RIF_variants_DF.alt_allele)]\n",
    "AR_INH_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_INH_variants_DF.ref_position , AR_INH_variants_DF.alt_allele)]\n",
    "AR_AMK_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_AMK_variants_DF.ref_position , AR_AMK_variants_DF.alt_allele)]\n",
    "AR_CAP_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_CAP_variants_DF.ref_position , AR_CAP_variants_DF.alt_allele)]\n",
    "AR_CIP_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_CIP_variants_DF.ref_position , AR_CIP_variants_DF.alt_allele)]\n",
    "AR_EMB_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_EMB_variants_DF.ref_position , AR_EMB_variants_DF.alt_allele)]\n",
    "AR_ETH_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_ETH_variants_DF.ref_position , AR_ETH_variants_DF.alt_allele)]\n",
    "AR_KAN_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_KAN_variants_DF.ref_position , AR_KAN_variants_DF.alt_allele)]\n",
    "AR_LEVO_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_LEVO_variants_DF.ref_position , AR_LEVO_variants_DF.alt_allele)]\n",
    "AR_OFLX_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_OFLX_variants_DF.ref_position , AR_OFLX_variants_DF.alt_allele)]\n",
    "AR_PAS_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_PAS_variants_DF.ref_position , AR_PAS_variants_DF.alt_allele)]\n",
    "AR_PZA_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_PZA_variants_DF.ref_position , AR_PZA_variants_DF.alt_allele)]\n",
    "AR_STR_variants = [str(ref_pos) + '_' + alt_allele for ref_pos, alt_allele in zip(AR_STR_variants_DF.ref_position , AR_STR_variants_DF.alt_allele)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Function* to Extract SNPs from VCF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNPs_from_VCF(VCF_file):\n",
    "\n",
    "    vcf_reader = vcf.Reader(open(VCF_file , 'r'))\n",
    "\n",
    "    #create dictionaries to store information for each call\n",
    "    ref_bases = {}\n",
    "    qry_bases = {}\n",
    "    ref_positions = {}\n",
    "    ## INFO_for_call = {}\n",
    "    \n",
    "    #indexer for dataframe containing SNPs\n",
    "    index = 0\n",
    "\n",
    "    #iterate through each Variant Call \n",
    "    for record in vcf_reader:\n",
    "\n",
    "        #check to see if the call is a PASS by Pilon\n",
    "        if record.FILTER == []:\n",
    "            \n",
    "            #check to see if SNP is located in a region associated with Antibiotic Resistance\n",
    "            if record.POS in H37Rv_positions_of_interest:\n",
    "\n",
    "                #check to see if variant is SNP; length of reference allele is 1, there is only 1 alternate allele, length of alternate allele is 1\n",
    "                if (len(record.REF) == 1) and (len(record.ALT) == 1) and (len(str( record.ALT[0] )) == 1):\n",
    "\n",
    "                        ##### Retrieve Relevant information for filtering quality of Base Call #####\n",
    "                        # Mean Base Quality @ locus\n",
    "                        BQ = record.INFO['BQ']\n",
    "                        # Mean Mapping Quality @ locus\n",
    "                        MQ = record.INFO['MQ']\n",
    "                        # Number of Reads w/ Deletion \n",
    "                        DC = record.INFO['DC']\n",
    "                        # Number of Reads w/ Insertion\n",
    "                        IC = record.INFO['IC']\n",
    "                        # Depth of Valid Reads in Pileup\n",
    "                        VD = record.INFO['DP']\n",
    "\n",
    "                        ### Filtering Criteria\n",
    "                        #---> Mean Base Quality > 20\n",
    "                        #---> Mean Mapping Quality > 30\n",
    "                        #---> No Reads Supporting Insertions\n",
    "                        #---> No Reads Supporting Deletions\n",
    "                        #---> Number of High Quality Reads >= 25\n",
    "                        if (BQ > 20) and (MQ > 30) and (DC == 0) and (IC == 0) and (VD >= 25): #SNP passed all filtering criteria!\n",
    "\n",
    "                            # Filtering Criteria for mutant allele frequency calculation (range: 0.75 - 1.0)\n",
    "                            ref_allele = str(record.REF)\n",
    "                            alt_allele = str(record.ALT[0])\n",
    "\n",
    "                            #After extensive filtering and categorization, store all of the pertinent information about the Base Call\n",
    "                            ref_bases[index] = ref_allele\n",
    "                            qry_bases[index] = alt_allele\n",
    "                            ref_positions[index] = record.POS\n",
    "                            ## INFO_for_call[index] = record.INFO\n",
    "\n",
    "                            index += 1\n",
    "                \n",
    "    #convert dictionaries to series\n",
    "    ref_bases = pd.Series(ref_bases)\n",
    "    qry_bases = pd.Series(qry_bases)\n",
    "    ref_positions = pd.Series(ref_positions)\n",
    "    ## INFO_for_call = pd.Series(INFO_for_call)\n",
    "\n",
    "    #create DataFrame to hold all base calls for a given sample\n",
    "    Variant_Call_DF = pd.DataFrame()\n",
    "    Variant_Call_DF['ref_base'] = ref_bases\n",
    "    Variant_Call_DF['alt_base'] = qry_bases\n",
    "    Variant_Call_DF['ref_position'] = ref_positions\n",
    "    ## Variant_Call_DF['INFO'] = INFO_for_call\n",
    "    \n",
    "    return Variant_Call_DF #DataFrame for base calls for a single isolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Functions* to Annotate SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Packages\n",
    "################################################################################################################################################################################################\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import Bio\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio import SeqIO\n",
    "from StringIO import StringIO\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.Seq import MutableSeq\n",
    "################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "# Relevant Information for H37Rv sequence SNP functional annotation\n",
    "################################################################################################################################################################################################\n",
    "####### Collect all DNA and Amino Acid sequences corresponding to genes on H37Rv #######\n",
    "#load reference genome and reference annotation\n",
    "reference_genome = '/n/data1/hms/dbmi/farhat/bin/work-horse/bin/h37rv.fasta'\n",
    "for reference_genome in SeqIO.parse(reference_genome, \"fasta\"):\n",
    "    reference_genome.seq.alphabet = IUPAC.unambiguous_dna\n",
    "\n",
    "reference_genome_annotation = pd.read_csv('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/H37Rv/h37rv_genome_summary.txt', '\\t').set_index('name')\n",
    "\n",
    "####### Function to translate coding DNA sequences ####### \n",
    "def translate(gene_id, sequence):\n",
    "\n",
    "    #find which strand the gene is located on and translate\n",
    "    strand = reference_genome_annotation.loc[gene_id, 'strand']\n",
    "    if strand == '+':\n",
    "        protein_sequence = sequence.translate(table=\"Bacterial\", cds=False)\n",
    "    elif strand == '-':\n",
    "        protein_sequence = sequence.reverse_complement().translate(table=\"Bacterial\", cds=False)\n",
    "\n",
    "    return protein_sequence\n",
    "\n",
    "####### Load in dictionaries for SNP annotation #######\n",
    "with open('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/pickled_files/dicts_for_SNP_annotation/H37Rv_gene_seq_records.pickle', 'rb') as handle:\n",
    "    ref_gene_sequences_records = pickle.load(handle)\n",
    "    \n",
    "with open('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/pickled_files/dicts_for_SNP_annotation/H37Rv_protein_seq_records.pickle', 'rb') as handle:\n",
    "    ref_protein_sequences_records = pickle.load(handle)\n",
    "    \n",
    "with open('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/pickled_files/dicts_for_SNP_annotation/H37Rv_coord_gene_mapping.pickle', 'rb') as handle:\n",
    "    ReferencePosition_Gene_mapping = pickle.load(handle)\n",
    "    \n",
    "####### get Gene Categories #######\n",
    "gene_categories = pd.read_csv('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/gene_categories/gene_categories.csv').set_index('name')\n",
    "gene_categories_dict = dict([gene_id , gene_category] for gene_id, gene_category in zip(list(gene_categories.gene_id) , list(gene_categories.Gene_Category)))\n",
    "\n",
    "####### get Gene Symbols #######\n",
    "gene_symbol_dict = dict([gene_id , gene_symbol] for gene_id, gene_symbol in zip(list(reference_genome_annotation.symbol.index) , list( reference_genome_annotation.symbol )))\n",
    "################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "# Function to annotate Intergenic SNPs\n",
    "################################################################################################################################################################################################\n",
    "def find_flanking_genes_for_intergenic_region(intergenic_ref_pos): \n",
    "\n",
    "    #this function finds the genes flagging an intergenic region given a reference position\n",
    "\n",
    "    #find gene immediately in the 5' direction\n",
    "    for i in range(0 , 100000):\n",
    "\n",
    "        #move toward 5' direction\n",
    "        if ReferencePosition_Gene_mapping[intergenic_ref_pos - i] != []:\n",
    "\n",
    "            gene_to_left = ReferencePosition_Gene_mapping[intergenic_ref_pos - i][0]\n",
    "            break\n",
    "\n",
    "    #find gene immediately in the 3' direction       \n",
    "    for i in range(0 , 100000):\n",
    "\n",
    "        #move toward 3' direction\n",
    "        try:\n",
    "            if ReferencePosition_Gene_mapping[intergenic_ref_pos + i] != []:\n",
    "\n",
    "                gene_to_right = ReferencePosition_Gene_mapping[intergenic_ref_pos + i][0]\n",
    "                break\n",
    "        \n",
    "        #KeyError means we have hit the 'end' of the chromosome, the intergenic region at then end of H37Rv in 5' > 3' orientation \n",
    "        #since TB chromosome is circular the gene to the 'right' is Rv0001    \n",
    "        except KeyError:\n",
    "            \n",
    "            gene_to_right = 'Rv0001'\n",
    "            break\n",
    "    \n",
    "    return gene_to_left + '_' + gene_to_right\n",
    "################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "# Function to determine whether SNPs are Synonymous or Non-Synonymous; Returns gene coordinate, codon position, AA changes, Gene Category & Symbol\n",
    "################################################################################################################################################################################################\n",
    "def SNP_annotate(ref_seq_position , alt_allele_i):\n",
    "    \n",
    "    '''\n",
    "    This function takes as input a reference position on H37Rv located within a \n",
    "    gene and an alternate allele and returns whether the base change \n",
    "    would correspond to a different Amino Acid sequence that results \n",
    "    from translating the DNA sequence into an AA sequence.\n",
    "    \n",
    "    '''\n",
    "    gene_intergenic_id_list = []\n",
    "    genomic_coord_list = []\n",
    "    gene_category_list = []\n",
    "    gene_symbol_list = []\n",
    "    Syn_NSyn_list = []\n",
    "    AA_change_list = []\n",
    "    \n",
    "    #get the Reference Allele from the complete H37Rv reference genome, indexing starts from 0\n",
    "    ref_allele_i = reference_genome.seq[int(ref_seq_position) - 1] \n",
    "    \n",
    "    #find the gene that SNP occurs on; check list corresponding to H37Rv coordinate to see if there are any genes associated with RefPosition\n",
    "    if len(ReferencePosition_Gene_mapping[ref_seq_position]) > 0:\n",
    "\n",
    "        #iterate through all genes that ReferencePosition is mapped to (i.e. SNP might correspond to 2 genes)\n",
    "        for gene_intergenic_id in ReferencePosition_Gene_mapping[ref_seq_position]:\n",
    "\n",
    "            #find genomic coordinate of SNP relative to gene (subtract 1 since reference seq starts counting at 1)\n",
    "            gene_relative_coord = (ref_seq_position - 1) - min( reference_genome_annotation.loc[gene_intergenic_id , 'chromStart'] , reference_genome_annotation.loc[gene_intergenic_id , 'chromEnd'] )\n",
    "            \n",
    "            #find the genomic coordinate (relative to the gene, in the 5' to 3' direction)\n",
    "            strand = reference_genome_annotation.loc[gene_intergenic_id, 'strand']\n",
    "            if strand == '+':\n",
    "                 genomic_5_to_3_coord = (ref_seq_position) - reference_genome_annotation.loc[gene_intergenic_id , 'chromStart']\n",
    "\n",
    "            elif strand == '-':\n",
    "                 genomic_5_to_3_coord = (reference_genome_annotation.loc[gene_intergenic_id , 'chromEnd']) - (ref_seq_position-1)\n",
    "                    \n",
    "            #find gene category (if one exists)\n",
    "            try:\n",
    "                gene_category_i = gene_categories_dict[gene_intergenic_id]\n",
    "            except KeyError:\n",
    "                gene_category_i = 'None'\n",
    "            \n",
    "            #find gene symbol (if one exists)\n",
    "            try:\n",
    "                gene_symbol_i = gene_symbol_dict[gene_intergenic_id]\n",
    "            except KeyError:\n",
    "                gene_symbol_i = 'None'\n",
    "            \n",
    "            #alternate allele is an actual base\n",
    "            if alt_allele_i in ['A','C','G','T']:\n",
    "\n",
    "                #translate into protein sequence with the SNP in place if not InDel or intergenic region\n",
    "                SNP_change = alt_allele_i\n",
    "\n",
    "                #ALTERNATE allele (is it Syn or NSyn?)\n",
    "                #get sequence from dictionary of sequences (and convert to mutable object)\n",
    "                test_gene_sequence = ref_gene_sequences_records[gene_intergenic_id].seq.tomutable()\n",
    "\n",
    "                #change reference gene sequence by the SNP in the query sequence\n",
    "                test_gene_sequence[int(gene_relative_coord)] = SNP_change\n",
    "\n",
    "                #convert back immutable object\n",
    "                test_gene_sequence = test_gene_sequence.toseq()\n",
    "\n",
    "                #translate sequence into amino acid seq\n",
    "                test_protein_sequence = translate(gene_intergenic_id , test_gene_sequence)\n",
    "\n",
    "                #store the H37Rv AA seq to compare against\n",
    "                H37Rv_AA_sequence = ref_protein_sequences_records[gene_intergenic_id].seq\n",
    "\n",
    "                #get the codon number where the SNP occurs within\n",
    "                ## take the genomic coordinate (relative to the gene, in the 5' to 3' direction), divide by 3, then take the ceiling of this number (will be fraction if SNP occurs in 1st or 2nd position on codon)\n",
    "                strand = reference_genome_annotation.loc[gene_intergenic_id, 'strand']\n",
    "                if strand == '+':\n",
    "                     genomic_5_to_3_coord = (ref_seq_position) - reference_genome_annotation.loc[gene_intergenic_id , 'chromStart']\n",
    "\n",
    "                elif strand == '-':\n",
    "                     genomic_5_to_3_coord = (reference_genome_annotation.loc[gene_intergenic_id , 'chromEnd']) - (ref_seq_position-1)\n",
    "\n",
    "                codon_coord = int(np.ceil( float( genomic_5_to_3_coord) / 3.0 ))\n",
    "\n",
    "                #compare to AA seq of original gene\n",
    "                if test_protein_sequence == H37Rv_AA_sequence:\n",
    "\n",
    "                    SNP_type = 'S'\n",
    "\n",
    "                    #get the AA before & after\n",
    "                    AA_change = H37Rv_AA_sequence[codon_coord-1] + str(codon_coord) + test_protein_sequence[codon_coord-1]\n",
    "\n",
    "                else:\n",
    "                    SNP_type = 'N'\n",
    "\n",
    "                    #get the AA before & after\n",
    "                    AA_change = H37Rv_AA_sequence[codon_coord-1] + str(codon_coord) + test_protein_sequence[codon_coord-1]\n",
    "                    \n",
    "            #alternate allele is a dummy (Base Call completely supports the Reference Allele)       \n",
    "            else:\n",
    "                \n",
    "                SNP_type = 'None'\n",
    "                AA_change = 'None'\n",
    "\n",
    "            #store relevant info in lists    \n",
    "            gene_intergenic_id_list.append(gene_intergenic_id)\n",
    "            genomic_coord_list.append(genomic_5_to_3_coord)\n",
    "            gene_category_list.append(gene_category_i)\n",
    "            gene_symbol_list.append(gene_symbol_i)\n",
    "            Syn_NSyn_list.append(SNP_type)\n",
    "            AA_change_list.append(AA_change)\n",
    "    \n",
    "    #if no gene in H37Rv corresponds to the Reference Position for SNP, then SNP must be intergenic\n",
    "    else:\n",
    "        \n",
    "        gene_intergenic_id = find_flanking_genes_for_intergenic_region(ref_seq_position)\n",
    "        genomic_5_to_3_coord = 'None'\n",
    "        gene_category_i = 'None'\n",
    "        gene_symbol_i = 'None'\n",
    "        SNP_type = 'I'\n",
    "        AA_change = 'None'\n",
    "        \n",
    "        #store relevant info in lists    \n",
    "        gene_intergenic_id_list.append(gene_intergenic_id)\n",
    "        genomic_coord_list.append(genomic_5_to_3_coord)\n",
    "        gene_category_list.append(gene_category_i)\n",
    "        gene_symbol_list.append(gene_symbol_i)\n",
    "        Syn_NSyn_list.append(SNP_type)\n",
    "        AA_change_list.append(AA_change)\n",
    "    \n",
    "    #if there is only a single gene associated with this SNP, just return the individual elememts\n",
    "    if len(gene_intergenic_id_list) == 1:\n",
    "        return [ref_allele_i , gene_intergenic_id , genomic_5_to_3_coord , gene_category_i , gene_symbol_i , SNP_type , AA_change]\n",
    "    \n",
    "    #else if there are two genes associated with this SNP, return elements for each SNP annotation in a list\n",
    "    elif len(gene_intergenic_id_list) > 1:\n",
    "        return [ref_allele_i , gene_intergenic_id_list , genomic_coord_list , gene_category_list , gene_symbol_list , Syn_NSyn_list , AA_change_list]\n",
    "################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce full VCF corresponding to each sample from each patient (deletes lines that correspond to Reference Positions where reads support the Reference Allele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "This script reduced the file of pilon-outputted VCF files by deleting blank lines\n",
    "(i.e. Reference Positions that have no variants)\n",
    "'''\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import subprocess as sp\n",
    "\n",
    "'''\n",
    "if len(sys.argv) != 2:\n",
    "    print \"::usage: %s <file_in.vcf> \" % sys.argv[0]\n",
    "    exit()\n",
    "\n",
    "print \"--reducing size of vcf file %s\" % sys.argv[1]\n",
    "'''\n",
    "\n",
    "with open(sys.argv[1]+\"_smallvcf\",\"w\") as outf:\n",
    "    with open(sys.argv[1],\"r\") as inp:\n",
    "        for line in inp:\n",
    "\n",
    "            #skip the comment lines\n",
    "            if line.startswith(\"#\"):\n",
    "                outf.write(line)\n",
    "                continue\n",
    "            data=line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            #if ALT is \".\" and the REF has only one base -> skip it\n",
    "            if ((len(data[3])==1) and (data[4]==\".\")):\n",
    "                continue\n",
    "            else:\n",
    "                outf.write(line)\n",
    "\n",
    "\n",
    "cmd=\"mv \"+sys.argv[1]+\"_smallvcf \"+sys.argv[1]\n",
    "print(cmd)\n",
    "sp.call(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Jobs to run script on each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slurmpy import Slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create BASH scripts to reduce VCF files of N isolates per job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_isolates_per_job = 20\n",
    "\n",
    "njobs = int( np.ceil( float( np.shape(sample_annotation)[0] ) / float(N_isolates_per_job) ) ) #number of jobs required if we split for every N isolates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print njobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_scripts = []\n",
    "\n",
    "#split jobs up into tasks of N\n",
    "num_isolates = 0\n",
    "commands_list = []\n",
    "total_isolate_count = 0\n",
    "for sample_tag in sample_annotation.tag:\n",
    "    \n",
    "    cmd_1 = 'cp /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/output/{0}/pilon/{0}.vcf /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/reduced_VCF_files_for_all_longitudinal_isolates'.format(sample_tag)\n",
    "    cmd_2 = 'python /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/python_scripts/reduce-pilon-vcf-size.py /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/reduced_VCF_files_for_all_longitudinal_isolates/{0}.vcf'.format(sample_tag)\n",
    "    \n",
    "    commands_list.append(cmd_1)\n",
    "    commands_list.append(cmd_2)\n",
    "    \n",
    "    num_isolates +=1 \n",
    "    total_isolate_count += 1\n",
    "    \n",
    "    if (num_isolates == N_isolates_per_job):\n",
    "        bash_scripts.append(commands_list)\n",
    "        num_isolates = 0\n",
    "        commands_list = []\n",
    "        \n",
    "    if total_isolate_count == 614: #add last few isolates\n",
    "        bash_scripts.append(commands_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit each job to O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693354\n",
      "submitted: Submitted batch job 20693355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED1 : 20693354\n",
      "VCF_RED2 : 20693355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED3 : 20693356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693357\n",
      "submitted: Submitted batch job 20693358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED4 : 20693357\n",
      "VCF_RED5 : 20693358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693359\n",
      "submitted: Submitted batch job 20693360\n",
      "submitted: Submitted batch job 20693361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED6 : 20693359\n",
      "VCF_RED7 : 20693360\n",
      "VCF_RED8 : 20693361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693362\n",
      "submitted: Submitted batch job 20693363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED9 : 20693362\n",
      "VCF_RED10 : 20693363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693364\n",
      "submitted: Submitted batch job 20693365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED11 : 20693364\n",
      "VCF_RED12 : 20693365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693366\n",
      "submitted: Submitted batch job 20693367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED13 : 20693366\n",
      "VCF_RED14 : 20693367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693368\n",
      "submitted: Submitted batch job 20693369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED15 : 20693368\n",
      "VCF_RED16 : 20693369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693370\n",
      "submitted: Submitted batch job 20693371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED17 : 20693370\n",
      "VCF_RED18 : 20693371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693372\n",
      "submitted: Submitted batch job 20693373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED19 : 20693372\n",
      "VCF_RED20 : 20693373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED21 : 20693374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693375\n",
      "submitted: Submitted batch job 20693376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED22 : 20693375\n",
      "VCF_RED23 : 20693376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693377\n",
      "submitted: Submitted batch job 20693378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED24 : 20693377\n",
      "VCF_RED25 : 20693378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693379\n",
      "submitted: Submitted batch job 20693380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED26 : 20693379\n",
      "VCF_RED27 : 20693380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693381\n",
      "submitted: Submitted batch job 20693382\n",
      "submitted: Submitted batch job 20693383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF_RED28 : 20693381\n",
      "VCF_RED29 : 20693382\n",
      "VCF_RED30 : 20693383\n",
      "VCF_RED31 : 20693384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 20693384\n"
     ]
    }
   ],
   "source": [
    "job_num = 1\n",
    "for job_i_commands_list in bash_scripts:\n",
    "    \n",
    "    #append all commands in a single string to be submitted as a job\n",
    "    VCF_reduce_job = ''\n",
    "    for command_i in job_i_commands_list:\n",
    "        VCF_reduce_job  = VCF_reduce_job  + '\\n' + command_i\n",
    "    \n",
    "    #directory where you want output + error files\n",
    "    os.chdir('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/reduced_VCF_files_for_all_longitudinal_isolates/O2_SLURM_logs/')\n",
    "\n",
    "    job_name = 'VCF_RED' + str(job_num)\n",
    "\n",
    "    s = Slurm(job_name , {'partition':'short' , 'N':'1' , 't':'0-12:00:00' , 'mem':'2G' , 'mail-type':'FAIL' , 'mail-user':'roger_vargas@g.harvard.edu'})\n",
    "\n",
    "    #submits the job\n",
    "    job_id = s.run(VCF_reduce_job)\n",
    "\n",
    "    print job_name  + ' : ' +  str(job_id)\n",
    "    job_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through Reduced VCF corresponding to each sample from each subject and collect all AR SNPs if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study Source</th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Sample Order</th>\n",
       "      <th>tag</th>\n",
       "      <th>Isolate Type</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Filtered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I0005973-8</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQFF00000000</td>\n",
       "      <td>Peru3062</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru3062</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>6/27/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005973-8</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQKH00000000</td>\n",
       "      <td>Peru3315</td>\n",
       "      <td>2</td>\n",
       "      <td>Peru3315</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>8/20/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005229-5</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQAO00000000</td>\n",
       "      <td>Peru2908</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru2908</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>3/30/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005229-5</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQKD00000000</td>\n",
       "      <td>Peru3278</td>\n",
       "      <td>2</td>\n",
       "      <td>Peru3278</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>8/6/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005235-2</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQBA00000000</td>\n",
       "      <td>Peru2921</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru2921</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>4/21/12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Study Source        Run ID Sample ID  Sample Order  \\\n",
       "Patient ID                                                              \n",
       "I0005973-8  Farhat et. al. 2019  MQFF00000000  Peru3062             1   \n",
       "I0005973-8  Farhat et. al. 2019  MQKH00000000  Peru3315             2   \n",
       "I0005229-5  Farhat et. al. 2019  MQAO00000000  Peru2908             1   \n",
       "I0005229-5  Farhat et. al. 2019  MQKD00000000  Peru3278             2   \n",
       "I0005235-2  Farhat et. al. 2019  MQBA00000000  Peru2921             1   \n",
       "\n",
       "                 tag          Isolate Type    Dates Filtered  \n",
       "Patient ID                                                    \n",
       "I0005973-8  Peru3062  Longitudinal Isolate  6/27/12      NaN  \n",
       "I0005973-8  Peru3315  Longitudinal Isolate  8/20/12      NaN  \n",
       "I0005229-5  Peru2908  Longitudinal Isolate  3/30/12      NaN  \n",
       "I0005229-5  Peru3278  Longitudinal Isolate   8/6/12      NaN  \n",
       "I0005235-2  Peru2921  Longitudinal Isolate  4/21/12      NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sample_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe to hold the AR SNPs detected in each isolate for each subject\n",
    "all_AR_SNPS_in_samples_df = pd.DataFrame()\n",
    "\n",
    "isolate_i = 0\n",
    "for isolate_tag in list(sample_annotation.tag):\n",
    "\n",
    "    #path to Reduced VCF file\n",
    "    Reduced_VCF_file = '/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/JankyPipe/reduced_VCF_files_for_all_longitudinal_isolates/' + isolate_tag + '.vcf'\n",
    "\n",
    "    #pull SNPs from VCF file\n",
    "    SNPs_from_isolate = SNPs_from_VCF(Reduced_VCF_file)\n",
    "    \n",
    "    ################################################################################\n",
    "    ### Annotate SNPs\n",
    "    ################################################################################\n",
    "\n",
    "    gene_id_list = []\n",
    "    gene_coord_list = []\n",
    "    gene_category_list = []\n",
    "    gene_symbol_list = []\n",
    "    SNP_ftype_list = []\n",
    "    AA_change_list = []\n",
    "\n",
    "    #Annotate Filtered Base Calls (make sure there is at least 1 SNP)\n",
    "    if np.shape(SNPs_from_isolate)[0] > 0:\n",
    "\n",
    "        for ref_position_i , alt_base_i in zip(list(SNPs_from_isolate.ref_position) , list(SNPs_from_isolate.alt_base)):\n",
    "\n",
    "            #annotate SNP\n",
    "            gene_id_i , gene_coord_i , gene_category_i , gene_symbol_i , SNP_ftype_i , AA_change_i = SNP_annotate(ref_position_i , alt_base_i)[1:]\n",
    "\n",
    "            gene_id_list.append(gene_id_i)\n",
    "            gene_coord_list.append(gene_coord_i)\n",
    "            gene_category_list.append(gene_category_i)\n",
    "            gene_symbol_list.append(gene_symbol_i)\n",
    "            SNP_ftype_list.append(SNP_ftype_i)\n",
    "            AA_change_list.append(AA_change_i)\n",
    "\n",
    "        #create columns to store SNP annotation info\n",
    "        SNPs_from_isolate['gene_id'] = gene_id_list\n",
    "        SNPs_from_isolate['gene_coord'] = gene_coord_list\n",
    "        SNPs_from_isolate['gene_category'] = gene_category_list\n",
    "        SNPs_from_isolate['gene_symbol'] = gene_symbol_list\n",
    "        SNPs_from_isolate['SNP_ftype'] = SNP_ftype_list\n",
    "        SNPs_from_isolate['AA_change'] = AA_change_list\n",
    "\n",
    "    #No predictive AR SNPs detected from this isolate (empty DataFrame)\n",
    "    else:\n",
    "\n",
    "        SNPs_from_isolate['gene_id'] = \"\"\n",
    "        SNPs_from_isolate['gene_coord'] = \"\"\n",
    "        SNPs_from_isolate['gene_category'] = \"\"\n",
    "        SNPs_from_isolate['gene_symbol'] = \"\"\n",
    "        SNPs_from_isolate['SNP_ftype'] = \"\"\n",
    "        SNPs_from_isolate['AA_change'] = \"\"\n",
    "        \n",
    "    #drop synonymous SNPs & re-index\n",
    "    SNPs_from_isolate = SNPs_from_isolate[SNPs_from_isolate.SNP_ftype != 'S']\n",
    "    SNPs_from_isolate.reset_index(inplace = True , drop = True)\n",
    "\n",
    "    #add column to patient_id & isolate tag\n",
    "    patient_id = sample_annotation[sample_annotation.tag == isolate_tag].index[0]\n",
    "    isolate_tag = sample_annotation[sample_annotation.tag == isolate_tag].tag[0]\n",
    "    \n",
    "    SNPs_from_isolate['patient_id'] = [patient_id]*np.shape(SNPs_from_isolate)[0]\n",
    "    SNPs_from_isolate['isolate_tag'] = [isolate_tag]*np.shape(SNPs_from_isolate)[0]\n",
    "    \n",
    "    #create a DataFrame that stores all AR SNPs detected across all of the samples\n",
    "    all_AR_SNPS_in_samples_df = all_AR_SNPS_in_samples_df.append(SNPs_from_isolate)\n",
    "    \n",
    "    isolate_i += 1\n",
    "    if isolate_i % 50 == 0:\n",
    "        print isolate_i\n",
    "        \n",
    "#reset index for DataFrame containing all AR SNPs in first clinical isoaltes for each serial pair\n",
    "all_AR_SNPS_in_samples_df.reset_index(inplace = True , drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_base</th>\n",
       "      <th>alt_base</th>\n",
       "      <th>ref_position</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_coord</th>\n",
       "      <th>gene_category</th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>SNP_ftype</th>\n",
       "      <th>AA_change</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>isolate_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>761110.0</td>\n",
       "      <td>Rv0667</td>\n",
       "      <td>1304</td>\n",
       "      <td>Antibiotic Resistance</td>\n",
       "      <td>rpoB</td>\n",
       "      <td>N</td>\n",
       "      <td>D435V</td>\n",
       "      <td>I0005973-8</td>\n",
       "      <td>Peru3062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>2155168.0</td>\n",
       "      <td>Rv1908c</td>\n",
       "      <td>944</td>\n",
       "      <td>Antibiotic Resistance</td>\n",
       "      <td>katG</td>\n",
       "      <td>N</td>\n",
       "      <td>S315T</td>\n",
       "      <td>I0005973-8</td>\n",
       "      <td>Peru3062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>2289213.0</td>\n",
       "      <td>Rv2043c</td>\n",
       "      <td>29</td>\n",
       "      <td>Antibiotic Resistance</td>\n",
       "      <td>pncA</td>\n",
       "      <td>N</td>\n",
       "      <td>Q10R</td>\n",
       "      <td>I0005973-8</td>\n",
       "      <td>Peru3062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>2518919.0</td>\n",
       "      <td>Rv2245</td>\n",
       "      <td>805</td>\n",
       "      <td>Antibiotic Resistance</td>\n",
       "      <td>kasA</td>\n",
       "      <td>N</td>\n",
       "      <td>G269S</td>\n",
       "      <td>I0005973-8</td>\n",
       "      <td>Peru3062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>4242182.0</td>\n",
       "      <td>Rv3793</td>\n",
       "      <td>2320</td>\n",
       "      <td>Antibiotic Resistance</td>\n",
       "      <td>embC</td>\n",
       "      <td>N</td>\n",
       "      <td>A774S</td>\n",
       "      <td>I0005973-8</td>\n",
       "      <td>Peru3062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ref_base alt_base  ref_position  gene_id gene_coord          gene_category  \\\n",
       "0        A        T      761110.0   Rv0667       1304  Antibiotic Resistance   \n",
       "1        C        G     2155168.0  Rv1908c        944  Antibiotic Resistance   \n",
       "2        T        C     2289213.0  Rv2043c         29  Antibiotic Resistance   \n",
       "3        G        A     2518919.0   Rv2245        805  Antibiotic Resistance   \n",
       "4        G        T     4242182.0   Rv3793       2320  Antibiotic Resistance   \n",
       "\n",
       "  gene_symbol SNP_ftype AA_change  patient_id isolate_tag  \n",
       "0        rpoB         N     D435V  I0005973-8    Peru3062  \n",
       "1        katG         N     S315T  I0005973-8    Peru3062  \n",
       "2        pncA         N      Q10R  I0005973-8    Peru3062  \n",
       "3        kasA         N     G269S  I0005973-8    Peru3062  \n",
       "4        embC         N     A774S  I0005973-8    Peru3062  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_AR_SNPS_in_samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1013, 11)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(all_AR_SNPS_in_samples_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out any *gid* E92D mutations since these are likely lineage markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_gid_E92D_SNPs_filter = [not ((all_AR_SNPS_in_samples_df.loc[SNP_i, :].AA_change == 'E92D') and (all_AR_SNPS_in_samples_df.loc[SNP_i, :].gene_id == 'Rv3919c')) for SNP_i in all_AR_SNPS_in_samples_df.index]\n",
    "all_AR_SNPS_in_samples_df = all_AR_SNPS_in_samples_df[non_gid_E92D_SNPs_filter]\n",
    "\n",
    "#reset index\n",
    "all_AR_SNPS_in_samples_df.reset_index(inplace = True , drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(915, 11)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(all_AR_SNPS_in_samples_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Genotype Drug Resistance classification for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIF_DR_list = []\n",
    "INH_DR_list = []\n",
    "AMK_DR_list = []\n",
    "CAP_DR_list = []\n",
    "CIP_DR_list = []\n",
    "EMB_DR_list = []\n",
    "ETH_DR_list = []\n",
    "KAN_DR_list = []\n",
    "LEVO_DR_list = []\n",
    "OFLX_DR_list = []\n",
    "PAS_DR_list = []\n",
    "PZA_DR_list = []\n",
    "STR_DR_list = []\n",
    "\n",
    "for sample_tag in sample_annotation.tag:\n",
    "    \n",
    "    RIF_i = 'S'\n",
    "    INH_i = 'S'\n",
    "    AMK_i = 'S'\n",
    "    CAP_i = 'S'\n",
    "    CIP_i = 'S'\n",
    "    EMB_i = 'S'\n",
    "    ETH_i = 'S'\n",
    "    KAN_i = 'S'\n",
    "    LEVO_i = 'S'\n",
    "    OFLX_i = 'S'\n",
    "    PAS_i = 'S'\n",
    "    PZA_i = 'S'\n",
    "    STR_i = 'S'\n",
    "    \n",
    "    #subset to AR SNPs detected in sample\n",
    "    all_AR_SNPS_sample_df_for_sample = all_AR_SNPS_in_samples_df[all_AR_SNPS_in_samples_df.isolate_tag == sample_tag]\n",
    "    \n",
    "    #create list of Ref Positions + Alternate Allele\n",
    "    all_AR_SNPS_sample_df_for_sample = [str(int(ref_pos)) + '_' + alt_allele for ref_pos, alt_allele in zip(all_AR_SNPS_sample_df_for_sample.ref_position , all_AR_SNPS_sample_df_for_sample.alt_base)]\n",
    "    \n",
    "    #check for SNP assoc. with resistance to different drugs\n",
    "    for AR_SNP in all_AR_SNPS_sample_df_for_sample:\n",
    "        \n",
    "        if AR_SNP in AR_RIF_variants:\n",
    "            RIF_i = 'R'\n",
    "        if AR_SNP in AR_INH_variants:\n",
    "            INH_i = 'R'\n",
    "        if AR_SNP in AR_AMK_variants:\n",
    "            AMK_i = 'R'\n",
    "        if AR_SNP in AR_CAP_variants:\n",
    "            CAP_i = 'R'\n",
    "        if AR_SNP in AR_CIP_variants:\n",
    "            CIP_i = 'R'\n",
    "        if AR_SNP in AR_EMB_variants:\n",
    "            EMB_i = 'R'\n",
    "        if AR_SNP in AR_ETH_variants:\n",
    "            ETH_i = 'R'\n",
    "        if AR_SNP in AR_KAN_variants:\n",
    "            KAN_i = 'R'\n",
    "        if AR_SNP in AR_LEVO_variants:\n",
    "            LEVO_i = 'R'\n",
    "        if AR_SNP in AR_OFLX_variants:\n",
    "            OFLX_i = 'R'\n",
    "        if AR_SNP in AR_PAS_variants:\n",
    "            PAS_i = 'R'\n",
    "        if AR_SNP in AR_PZA_variants:\n",
    "            PZA_i = 'R'\n",
    "        if AR_SNP in AR_STR_variants:\n",
    "            STR_i = 'R'\n",
    "            \n",
    "    RIF_DR_list.append(RIF_i)\n",
    "    INH_DR_list.append(INH_i)\n",
    "    AMK_DR_list.append(AMK_i)\n",
    "    CAP_DR_list.append(CAP_i)\n",
    "    CIP_DR_list.append(CIP_i)\n",
    "    EMB_DR_list.append(EMB_i)\n",
    "    ETH_DR_list.append(ETH_i)\n",
    "    KAN_DR_list.append(KAN_i)\n",
    "    LEVO_DR_list.append(LEVO_i)\n",
    "    OFLX_DR_list.append(OFLX_i)\n",
    "    PAS_DR_list.append(PAS_i)\n",
    "    PZA_DR_list.append(PZA_i)\n",
    "    STR_DR_list.append(STR_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotation.loc[: , 'RIF'] = RIF_DR_list\n",
    "sample_annotation.loc[: , 'INH'] = INH_DR_list\n",
    "sample_annotation.loc[: , 'AMK'] = AMK_DR_list\n",
    "sample_annotation.loc[: , 'CAP'] = CAP_DR_list\n",
    "sample_annotation.loc[: , 'CIP'] = CIP_DR_list\n",
    "sample_annotation.loc[: , 'EMB'] = EMB_DR_list\n",
    "sample_annotation.loc[: , 'ETH'] = ETH_DR_list\n",
    "sample_annotation.loc[: , 'KAN'] = KAN_DR_list\n",
    "sample_annotation.loc[: , 'LEVO'] = LEVO_DR_list\n",
    "sample_annotation.loc[: , 'OFLX'] = OFLX_DR_list\n",
    "sample_annotation.loc[: , 'PAS'] = PAS_DR_list\n",
    "sample_annotation.loc[: , 'PZA'] = PZA_DR_list\n",
    "sample_annotation.loc[: , 'STR'] = STR_DR_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study Source</th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Sample Order</th>\n",
       "      <th>tag</th>\n",
       "      <th>Isolate Type</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Filtered</th>\n",
       "      <th>RIF</th>\n",
       "      <th>INH</th>\n",
       "      <th>...</th>\n",
       "      <th>CAP</th>\n",
       "      <th>CIP</th>\n",
       "      <th>EMB</th>\n",
       "      <th>ETH</th>\n",
       "      <th>KAN</th>\n",
       "      <th>LEVO</th>\n",
       "      <th>OFLX</th>\n",
       "      <th>PAS</th>\n",
       "      <th>PZA</th>\n",
       "      <th>STR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I0005973-8</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQFF00000000</td>\n",
       "      <td>Peru3062</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru3062</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>6/27/12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005973-8</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQKH00000000</td>\n",
       "      <td>Peru3315</td>\n",
       "      <td>2</td>\n",
       "      <td>Peru3315</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>8/20/12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005229-5</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQAO00000000</td>\n",
       "      <td>Peru2908</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru2908</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>3/30/12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005229-5</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQKD00000000</td>\n",
       "      <td>Peru3278</td>\n",
       "      <td>2</td>\n",
       "      <td>Peru3278</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>8/6/12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I0005235-2</th>\n",
       "      <td>Farhat et. al. 2019</td>\n",
       "      <td>MQBA00000000</td>\n",
       "      <td>Peru2921</td>\n",
       "      <td>1</td>\n",
       "      <td>Peru2921</td>\n",
       "      <td>Longitudinal Isolate</td>\n",
       "      <td>4/21/12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Study Source        Run ID Sample ID  Sample Order  \\\n",
       "Patient ID                                                              \n",
       "I0005973-8  Farhat et. al. 2019  MQFF00000000  Peru3062             1   \n",
       "I0005973-8  Farhat et. al. 2019  MQKH00000000  Peru3315             2   \n",
       "I0005229-5  Farhat et. al. 2019  MQAO00000000  Peru2908             1   \n",
       "I0005229-5  Farhat et. al. 2019  MQKD00000000  Peru3278             2   \n",
       "I0005235-2  Farhat et. al. 2019  MQBA00000000  Peru2921             1   \n",
       "\n",
       "                 tag          Isolate Type    Dates Filtered RIF INH ... CAP  \\\n",
       "Patient ID                                                           ...       \n",
       "I0005973-8  Peru3062  Longitudinal Isolate  6/27/12      NaN   R   R ...   S   \n",
       "I0005973-8  Peru3315  Longitudinal Isolate  8/20/12      NaN   R   R ...   S   \n",
       "I0005229-5  Peru2908  Longitudinal Isolate  3/30/12      NaN   R   R ...   S   \n",
       "I0005229-5  Peru3278  Longitudinal Isolate   8/6/12      NaN   R   R ...   S   \n",
       "I0005235-2  Peru2921  Longitudinal Isolate  4/21/12      NaN   R   R ...   S   \n",
       "\n",
       "           CIP EMB ETH KAN LEVO OFLX PAS PZA STR  \n",
       "Patient ID                                        \n",
       "I0005973-8   S   S   S   S    S    S   S   S   S  \n",
       "I0005973-8   S   S   S   S    S    S   S   S   S  \n",
       "I0005229-5   S   S   S   S    S    S   S   S   S  \n",
       "I0005229-5   S   S   S   S    S    S   S   S   S  \n",
       "I0005235-2   R   S   S   S    R    R   S   S   S  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotation.to_csv('/n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/CSV_files/sample_annotation_files/Table S2B after DR genotyping.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
